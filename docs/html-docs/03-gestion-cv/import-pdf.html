<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Import PDF | FitMyCV.io</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../assets/css/style.css?v=1.0.4">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
  <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
  <script>mermaid.initialize({ startOnLoad: false });</script>
</head>
<body>
  <div class="layout">
    <div id="sidebar-container"></div>
    <main class="main">
      <div id="header-container"></div>
      <div class="content">

        <div class="breadcrumb">
          <a href="../index.html">Docs</a>
          <span>/</span>
          <a href="./overview.html">Gestion CV</a>
          <span>/</span>
          <span>Import PDF</span>
        </div>

        <h1>Import PDF</h1>
        <p class="lead">
          Le systeme d'import PDF utilise l'API Vision de GPT-4o pour extraire et structurer les informations d'un CV au format PDF vers le format JSON standardise (<code>data/schema.json</code>).
        </p>

        <div class="callout callout-info">
          <div class="callout-title">Cout</div>
          <p>Credits debites selon le plan de l'utilisateur. Le credit est debite au lancement via <code>incrementFeatureCounter(userId, 'import_pdf')</code> et rembourse en cas d'echec.</p>
        </div>

        <!-- ============================================ -->
        <!-- PIPELINE D'IMPORT                            -->
        <!-- ============================================ -->

        <h2>Pipeline d'Import</h2>

        <div class="diagram">
          <div class="diagram-title">Flux d'import PDF</div>
          <div class="mermaid">
flowchart TB
    subgraph Input["ENTREE"]
        PDF["PDF uploade"]
    end

    subgraph Process["TRAITEMENT"]
        Upload["Upload et Validation<br/>type, taille"]
        Convert["Conversion images<br/>pdf2pic + sharp"]
        Vision["GPT-4o Vision<br/>Extraction structuree"]
        Parse["Parsing JSON<br/>+ sanitization null bytes"]
        Reconstruct["Reconstruction CV<br/>reconstructCv"]
    end

    subgraph Output["SORTIE"]
        CvFile["CvFile cree<br/>+ source enregistree"]
        ErrorNode["Erreur + Remboursement"]
    end

    PDF --> Upload
    Upload --> Convert
    Convert --> Vision
    Vision --> Parse
    Parse --> Reconstruct
    Reconstruct -->|"Valide"| CvFile
    Reconstruct -->|"Invalide"| ErrorNode

    style PDF fill:#0ea5e9,stroke:#0284c7,color:#fff
    style Upload fill:#8b5cf6,stroke:#7c3aed,color:#fff
    style Convert fill:#8b5cf6,stroke:#7c3aed,color:#fff
    style Vision fill:#6366f1,stroke:#4f46e5,color:#fff
    style Parse fill:#8b5cf6,stroke:#7c3aed,color:#fff
    style Reconstruct fill:#f59e0b,stroke:#d97706,color:#fff
    style CvFile fill:#22c55e,stroke:#16a34a,color:#fff
    style ErrorNode fill:#ef4444,stroke:#dc2626,color:#fff
          </div>
        </div>

        <!-- ============================================ -->
        <!-- DATA FLOW DETAILLE                           -->
        <!-- ============================================ -->

        <h2>Data Flow Detaille</h2>

        <!-- ETAPE 1 -->
        <h3>Etape 1 : Upload et Validation</h3>

        <div class="data-flow">
          <div class="data-flow-header">
            <span class="data-flow-badge input">INPUT</span>
            <span class="data-flow-title">Fichier PDF</span>
          </div>
          <div class="data-flow-content">
            <h5>Validation</h5>
            <ul>
              <li>Type MIME : <code>application/pdf</code></li>
              <li>Taille max : <strong>10 MB</strong></li>
              <li>Pages max : <strong>10 pages</strong> (configurable via Settings <code>pdf_import.maxPages</code>)</li>
            </ul>
            <h5>Source</h5>
            <p>Upload formulaire <code>multipart/form-data</code> vers <code>POST /api/background-tasks/import-pdf</code></p>

            <pre><code class="language-javascript">// app/api/background-tasks/import-pdf/route.js
const validation = await validateUploadedFile(pdfFile, {
  allowedTypes: ['application/pdf'],
  maxSize: 10 * 1024 * 1024, // 10 MB
});

if (!validation.valid) {
  return NextResponse.json({ error: validation.error }, { status: 400 });
}

// Debit du credit avant lancement
const usageResult = await incrementFeatureCounter(userId, 'import_pdf', {
  taskId: taskIdentifier
});</code></pre>

            <h5>Execution asynchrone</h5>
            <p>L'import est execute en tache de fond via <code>scheduleImportPdfJob()</code>. L'API retourne immediatement un <code>taskId</code> (HTTP 202) et le client suit la progression via polling.</p>
          </div>
        </div>

        <!-- ETAPE 2 -->
        <h3>Etape 2 : Conversion en Images</h3>

        <div class="data-flow">
          <div class="data-flow-header">
            <span class="data-flow-badge process">PROCESS</span>
            <span class="data-flow-title">PDF &rarr; Images JPEG</span>
          </div>
          <div class="data-flow-content">
            <h5>Librairies</h5>
            <ul>
              <li><code>pdf2pic</code> (<code>fromPath</code>) : conversion PDF vers images via ImageMagick</li>
              <li><code>sharp</code> : resize, trim des marges blanches, compression JPEG</li>
            </ul>

            <h5>Configuration (depuis Settings)</h5>
            <table>
              <thead>
                <tr>
                  <th>Parametre</th>
                  <th>Defaut</th>
                  <th>Setting</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Largeur max</td>
                  <td>1000 px</td>
                  <td><code>pdf_image_max_width</code></td>
                </tr>
                <tr>
                  <td>Densite (DPI)</td>
                  <td>100</td>
                  <td><code>pdf_image_density</code></td>
                </tr>
                <tr>
                  <td>Qualite JPEG</td>
                  <td>75</td>
                  <td><code>pdf_image_quality</code></td>
                </tr>
                <tr>
                  <td>Detail Vision</td>
                  <td>high</td>
                  <td><code>pdf_vision_detail</code></td>
                </tr>
              </tbody>
            </table>

            <pre><code class="language-javascript">// lib/openai-core/pdfToImages.js
import { fromPath } from 'pdf2pic';
import sharp from 'sharp';

export async function convertPdfToImages(pdfPath, options = {}) {
  const converter = fromPath(pdfPath, {
    density: options.density || 100,
    format: 'jpeg',
    width: maxWidth * 2,
    preserveAspectRatio: true,
    graphicsMagick: false, // Utiliser ImageMagick
  });

  const results = await converter.bulk(-1, { responseType: 'buffer' });

  const base64Images = await Promise.all(
    results.map(async (result) => {
      // Resize PUIS trim = 4x moins de pixels a analyser
      const resizedBuffer = await sharp(result.buffer)
        .resize({ width: maxWidth, withoutEnlargement: true, fit: 'inside' })
        .trim({ threshold: 10 })
        .jpeg({ quality })
        .toBuffer();

      return resizedBuffer.toString('base64');
    })
  );

  return base64Images.filter(img => img !== null);
}</code></pre>

            <h5>Output</h5>
            <p>Array de strings base64 JPEG (1 par page, compressees et trimmees).</p>
          </div>
        </div>

        <!-- ETAPE 3 -->
        <h3>Etape 3 : Extraction IA (GPT-4o Vision)</h3>

        <div class="data-flow">
          <div class="data-flow-header">
            <span class="data-flow-badge ai">IA</span>
            <span class="data-flow-title">GPT-4o Vision - Structured Outputs</span>
          </div>
          <div class="data-flow-content">
            <h5>Modele</h5>
            <p>Configurable via Settings : <code>model_import_pdf</code> (standard) ou <code>model_first_import_pdf</code> (premier import d'un utilisateur). Par defaut GPT-4o.</p>

            <h5>Prompts</h5>
            <ul>
              <li><strong>System</strong> : <code>lib/features/import-pdf/prompts/system.md</code> &mdash; regles d'extraction, classification skills, chain-of-thought avec section <code>reasoning</code></li>
              <li><strong>User</strong> : <code>lib/features/import-pdf/prompts/user.md</code> &mdash; instruction simple de retour</li>
            </ul>

            <h5>Input (Messages)</h5>
            <pre><code class="language-json">[
  {
    "role": "system",
    "content": "# CV EXTRACTION EXPERT\nYou are an expert at extracting structured data..."
  },
  {
    "role": "user",
    "content": [
      { "type": "text", "text": "Return ONLY the extracted CV content..." },
      {
        "type": "image_url",
        "image_url": {
          "url": "data:image/jpeg;base64,{page1}",
          "detail": "high"
        }
      }
    ]
  }
]</code></pre>

            <h5>Structured Outputs (response_format)</h5>
            <p>Le schema <code>cvExtractionSchema.json</code> utilise <code>"strict": true</code> pour garantir un JSON valide. Il inclut une section <code>reasoning</code> (chain-of-thought) que le modele remplit AVANT l'extraction :</p>

            <pre><code class="language-json">{
  "name": "cv_content_extraction",
  "strict": true,
  "schema": {
    "type": "object",
    "properties": {
      "reasoning": {
        "properties": {
          "document_structure": { "type": "string" },
          "detected_language": { "type": "string", "enum": ["fr", "en", "es", "de"] },
          "language_confirmation": { "type": "string" },
          "ocr_issues": { "type": ["string", "null"] },
          "skills_analysis": { "type": "string" },
          "extraction_strategy": { "type": "string" }
        }
      },
      "header": { "..." },
      "summary": { "..." },
      "skills": { "..." },
      "experience": { "..." },
      "education": { "..." },
      "languages": { "..." },
      "extras": { "..." },
      "projects": { "..." }
    },
    "required": ["reasoning", "header", "summary", "skills", "experience",
                  "education", "languages", "extras", "projects"]
  }
}</code></pre>

            <h5>Parametres GPT</h5>
            <table>
              <thead>
                <tr>
                  <th>Parametre</th>
                  <th>Defaut</th>
                  <th>Setting</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Temperature</td>
                  <td>0.1</td>
                  <td><code>temperature_import_pdf</code></td>
                </tr>
                <tr>
                  <td>Top P</td>
                  <td>1</td>
                  <td><code>top_p_import_pdf</code></td>
                </tr>
                <tr>
                  <td>Seed</td>
                  <td>0 (desactive)</td>
                  <td><code>seed_import_pdf</code></td>
                </tr>
                <tr>
                  <td>Max tokens</td>
                  <td>4096</td>
                  <td>Non configurable</td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>

        <!-- ETAPE 4 -->
        <h3>Etape 4 : Reconstruction CV</h3>

        <div class="data-flow">
          <div class="data-flow-header">
            <span class="data-flow-badge process">PROCESS</span>
            <span class="data-flow-title">reconstructCv()</span>
          </div>
          <div class="data-flow-content">
            <h5>Module</h5>
            <p><code>lib/cv-core/reconstruction.js</code></p>

            <h5>Traitement</h5>
            <p><code>reconstructCv()</code> reconstruit le CV a partir des donnees extraites (sparse) et garantit la presence des 8 sections avec leur structure standardisee :</p>

            <pre><code class="language-javascript">// lib/cv-core/reconstruction.js
export async function reconstructCv(extracted) {
  return {
    header: reconstructHeader(extracted.header),
    summary: reconstructSummary(extracted.summary),
    skills: extracted.skills || getEmptySkills(),
    experience: reconstructExperiences(extracted.experience || []),
    education: reconstructEducation(extracted.education || []),
    languages: extracted.languages || [],
    extras: extracted.extras || [],
    projects: reconstructProjects(extracted.projects || []),
  };
}</code></pre>

            <h5>Reconstructions par section</h5>
            <ul>
              <li><strong>header</strong> : Reconstruit <code>contact.location</code> imbrique depuis les champs plats (<code>city</code>, <code>region</code>, <code>country_code</code>)</li>
              <li><strong>experience</strong> : Reconstruit <code>location</code> imbrique, assure la presence de <code>responsibilities</code>, <code>deliverables</code>, <code>skills_used</code></li>
              <li><strong>education</strong> : Reconstruit <code>location</code> imbrique depuis champs plats</li>
              <li><strong>projects</strong> : Assure <code>tech_stack</code> comme array</li>
              <li><strong>summary, skills, languages, extras</strong> : Valeurs par defaut si absent</li>
            </ul>

            <h5>Langue</h5>
            <p>La langue est detectee par le modele via la section <code>reasoning.detected_language</code> et stockee dans <code>CvFile.language</code> (pas dans le JSON).</p>
          </div>
        </div>

        <!-- ETAPE 5 -->
        <h3>Etape 5 : Sauvegarde</h3>

        <div class="data-flow">
          <div class="data-flow-header">
            <span class="data-flow-badge output">OUTPUT</span>
            <span class="data-flow-title">CvFile cree</span>
          </div>
          <div class="data-flow-content">
            <h5>Stockage fichier</h5>
            <pre><code class="language-javascript">// lib/features/import-pdf/job.js (handleResult)
const filename = `${DateTime.now().toFormat('yyyyMMddHHmmssSSS')}.json`;

// Ecrire le fichier JSON sur le filesystem
await writeUserCvFile(userId, filename, cvContent);

// Creer l'entree en base
await prisma.cvFile.upsert({
  where: { userId_filename: { userId, filename } },
  update: { language: detectedLanguage },
  create: { userId, filename, language: detectedLanguage },
});</code></pre>

            <h5>Source enregistree</h5>
            <pre><code class="language-javascript">// Enregistrer la source PDF
await setCvSource(userId, filename, 'pdf', pdfFileName, 'import-pdf', null);
// sourceType: 'pdf'
// sourceValue: nom du fichier PDF original
// createdBy: 'import-pdf'</code></pre>

            <h5>Validation du contenu</h5>
            <p>Avant la sauvegarde, le job verifie que le CV extrait contient au minimum un <code>full_name</code> et un <code>current_title</code> non vides. Si le CV est vide, l'import est rejete avec remboursement.</p>
          </div>
        </div>

        <!-- ============================================ -->
        <!-- SCHEMA DE SORTIE                             -->
        <!-- ============================================ -->

        <h2>Schema de sortie</h2>

        <p>Le CV JSON produit suit le schema <code>data/schema.json</code> avec 8 sections de contenu pur. Les metadonnees (<code>language</code>, <code>createdBy</code>, <code>sourceType</code>) sont stockees en DB sur le modele <code>CvFile</code>, pas dans le JSON.</p>

        <pre><code class="language-json">{
  "header": {
    "full_name": "Jean Dupont",
    "current_title": "Developpeur Full Stack Senior",
    "contact": {
      "email": "jean.dupont@email.com",
      "phone": "+33 6 12 34 56 78",
      "location": {
        "city": "Paris",
        "region": "Ile-de-France",
        "country_code": "FR"
      },
      "links": [
        { "label": "LinkedIn", "url": "https://linkedin.com/in/jeandupont" },
        { "label": "GitHub", "url": "https://github.com/jeandupont" }
      ]
    }
  },
  "summary": {
    "description": "Developpeur Full Stack avec 8 ans d'experience..."
  },
  "skills": {
    "hard_skills": [
      { "name": "JavaScript", "proficiency": 5 },
      { "name": "Python", "proficiency": 4 }
    ],
    "tools": [
      { "name": "Docker", "proficiency": 3 },
      { "name": "PostgreSQL", "proficiency": 4 }
    ],
    "methodologies": ["Agile", "Scrum", "CI/CD"],
    "soft_skills": ["Leadership", "Communication"]
  },
  "experience": [
    {
      "title": "Developpeur Full Stack Senior",
      "company": "TechCorp",
      "department_or_client": "Direction IT",
      "start_date": "2021-03",
      "end_date": null,
      "location": { "city": "Paris", "region": "Ile-de-France", "country_code": "FR" },
      "description": "Conception et maintenance d'applications web critiques.",
      "responsibilities": ["Developpement d'APIs REST", "Revue de code"],
      "deliverables": ["Reduction du temps de reponse de 40%"],
      "skills_used": ["JavaScript", "React", "Node.js"]
    }
  ],
  "education": [
    {
      "institution": "Universite Paris-Saclay",
      "degree": "Master",
      "field_of_study": "Informatique",
      "location": { "city": "Paris", "region": "Ile-de-France", "country_code": "FR" },
      "start_date": "2013-09",
      "end_date": "2015-06"
    }
  ],
  "languages": [
    { "name": "Francais", "level": "Langue maternelle" },
    { "name": "Anglais", "level": "C1" }
  ],
  "extras": [
    { "name": "Permis", "summary": "B" },
    { "name": "Centres d'interet", "summary": "Course a pied, Photographie" }
  ],
  "projects": [
    {
      "name": "Mon Portfolio",
      "role": "Developpeur",
      "summary": "Site web personnel avec blog technique.",
      "tech_stack": ["Next.js", "Tailwind CSS"],
      "start_date": "2023-01",
      "end_date": "2023-03"
    }
  ]
}</code></pre>

        <!-- ============================================ -->
        <!-- GESTION DES ERREURS                          -->
        <!-- ============================================ -->

        <h2>Gestion des Erreurs</h2>

        <table>
          <thead>
            <tr>
              <th>Erreur</th>
              <th>Cause</th>
              <th>Action</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>INVALID_FILE_TYPE</code></td>
              <td>Fichier non-PDF</td>
              <td>Rejet immediat, pas de debit</td>
            </tr>
            <tr>
              <td><code>FILE_TOO_LARGE</code></td>
              <td>PDF &gt; 10 MB</td>
              <td>Rejet immediat, pas de debit</td>
            </tr>
            <tr>
              <td><code>pdfTooManyPages</code></td>
              <td>PDF &gt; 10 pages</td>
              <td>Rejet immediat, pas de debit</td>
            </tr>
            <tr>
              <td><code>EXTRACTION_FAILED</code></td>
              <td>Echec GPT-4o (timeout, erreur API)</td>
              <td>Remboursement credits</td>
            </tr>
            <tr>
              <td><code>VALIDATION_FAILED</code></td>
              <td>JSON invalide ou CV vide (pas de <code>full_name</code>/<code>current_title</code>)</td>
              <td>Remboursement credits</td>
            </tr>
            <tr>
              <td><code>pdfConversionFailed</code></td>
              <td>Echec conversion PDF &rarr; images (ImageMagick)</td>
              <td>Remboursement credits</td>
            </tr>
            <tr>
              <td><code>Task cancelled</code></td>
              <td>Annulation par l'utilisateur via AbortSignal</td>
              <td>Remboursement credits</td>
            </tr>
          </tbody>
        </table>

        <!-- ============================================ -->
        <!-- MONITORING                                   -->
        <!-- ============================================ -->

        <h2>Monitoring</h2>

        <p>Chaque import est tracke dans <code>OpenAIUsageLog</code> via <code>trackOpenAIUsage()</code> :</p>

        <pre><code class="language-javascript">// lib/features/import-pdf/service.js
await trackOpenAIUsage({
  userId,
  featureName: isFirstImport ? 'first_import_pdf' : 'import_pdf',
  model,                                        // ex: 'gpt-4o'
  promptTokens: result.usage.prompt_tokens,      // Images = beaucoup de tokens
  completionTokens: result.usage.completion_tokens,
  cachedTokens: result.usage.prompt_tokens_details?.cached_tokens || 0,
  duration: result.duration,                     // en ms
});</code></pre>

        <p>Le tracking distingue le premier import (<code>first_import_pdf</code>) des imports suivants (<code>import_pdf</code>) pour permettre l'utilisation d'un modele different (potentiellement plus performant) pour le premier import.</p>

        <p>Un second tracking via <code>trackCvImport()</code> enregistre les metriques cote telemetrie serveur :</p>

        <pre><code class="language-javascript">// lib/features/import-pdf/job.js (trackSuccess)
await trackCvImport({
  userId,
  deviceId,
  fileSize,          // Taille du PDF original
  duration,          // Duree totale du job
  status: 'success', // ou 'error'
  isFirstImport,
});</code></pre>

        <!-- ============================================ -->
        <!-- FICHIERS CLES                                -->
        <!-- ============================================ -->

        <h2>Fichiers Cles</h2>

        <table>
          <thead>
            <tr>
              <th>Fichier</th>
              <th>Role</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>app/api/background-tasks/import-pdf/route.js</code></td>
              <td>API endpoint : validation, debit credits, scheduling du job</td>
            </tr>
            <tr>
              <td><code>lib/features/import-pdf/job.js</code></td>
              <td>Job runner : orchestration, sauvegarde CvFile, tracking</td>
            </tr>
            <tr>
              <td><code>lib/features/import-pdf/service.js</code></td>
              <td>Service principal : appel Vision API, parsing, reconstruction</td>
            </tr>
            <tr>
              <td><code>lib/features/import-pdf/prompts/system.md</code></td>
              <td>Prompt systeme : regles d'extraction, chain-of-thought, classification</td>
            </tr>
            <tr>
              <td><code>lib/features/import-pdf/schemas/cvExtractionSchema.json</code></td>
              <td>JSON Schema pour Structured Outputs (contenu pur + reasoning)</td>
            </tr>
            <tr>
              <td><code>lib/openai-core/pdfToImages.js</code></td>
              <td>Conversion PDF &rarr; images JPEG via pdf2pic + sharp</td>
            </tr>
            <tr>
              <td><code>lib/cv-core/reconstruction.js</code></td>
              <td>Reconstruction CV depuis donnees extraites (8 sections)</td>
            </tr>
            <tr>
              <td><code>lib/cv-core/source.js</code></td>
              <td>Enregistrement source : <code>setCvSource()</code> avec sourceType/createdBy</td>
            </tr>
            <tr>
              <td><code>data/schema.json</code></td>
              <td>Schema JSON de reference du format CV (8 sections)</td>
            </tr>
          </tbody>
        </table>

        <!-- ============================================ -->
        <!-- EXPORT PDF                                   -->
        <!-- ============================================ -->

        <h2>Export PDF</h2>

        <p>L'export PDF (generation d'un PDF a partir du CV JSON) utilise un pipeline distinct base sur le rendu HTML via Puppeteer.</p>

        <table>
          <thead>
            <tr>
              <th>Module</th>
              <th>Role</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>lib/pdf/index.js</code></td>
              <td>Exports publics : styles, translations, utils, generators</td>
            </tr>
            <tr>
              <td><code>lib/pdf/cvStyles.js</code></td>
              <td>CSS styling : <code>getBaseStyles()</code> + <code>getExportStyles()</code> + <code>getPreviewStyles()</code></td>
            </tr>
            <tr>
              <td><code>lib/pdf/cvTranslations.js</code></td>
              <td>Traductions FR/EN/ES/DE, niveaux de competence via <code>createTranslator()</code></td>
            </tr>
            <tr>
              <td><code>lib/pdf/cvUtils.js</code></td>
              <td>Utilitaires : <code>formatDate()</code>, <code>sortExperiences()</code>, <code>prepareCvData()</code></td>
            </tr>
            <tr>
              <td><code>lib/pdf/sectionGenerators.js</code></td>
              <td>Generateurs HTML par section via <code>createSectionGenerators()</code></td>
            </tr>
          </tbody>
        </table>

        <h5>Architecture de l'export</h5>
        <ul>
          <li><code>prepareCvData()</code> trie les experiences/education par date et filtre selon les selections</li>
          <li><code>createSectionGenerators()</code> cree un objet avec un generateur HTML par section (summary, skills, experience, education, languages, projects, extras)</li>
          <li><code>generateSectionsHtml()</code> assemble les sections dans l'ordre defini par <code>DEFAULT_SECTION_ORDER</code></li>
          <li>Supporte 4 langues (FR, EN, ES, DE) via <code>createTranslator(language)</code></li>
        </ul>

      </div>
    </main>
  </div>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-javascript.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-typescript.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-jsx.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-tsx.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-sql.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-yaml.min.js"></script>
  <script src="../assets/js/layout.js?v=1.0.4"></script>
  <script src="../assets/js/main.js?v=1.0.4"></script>
</body>
</html>
